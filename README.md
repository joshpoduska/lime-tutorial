### Explanatory and Interpretable Modeling

Model consumers and model stakeholders need to trust model recommendations and understand how to incorporate them into their decision making. Without trust and understanding, models run a real risk of becoming shelf-ware or being misused. Legislation like GDPR in the EU and the FUTURE of AI Act in the US may soon require model explainability. Additionally, the growing awareness of model ethics and bias will place an emphasis on explainable models. 

Because of these realities, an understanding of the concepts around model explainability is vital to the success of any data scientist or data science organizational strategy. 

### Project Components
* <a href="Tutorial-continuous-and-categorical-features.ipynb" target="_blank">Tutorial-continuous-and-categorical-features.ipynb</a> walks through the lime package and provides detailed explanations for how lime opperates.
* <a href="Tutorial-Image-Classification-Keras.ipynb" target="_blank">Tutorial-Image-Classification-Keras.ipynb</a> provides further examples of lime in action, this time with image data.
